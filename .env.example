# LLM Provider Configuration
# Options: groq, ollama, bedrock
LLM_PROVIDER=groq

# Groq Configuration (Cloud LLM - Fast & Reliable)
GROQ_API_KEY=your_groq_api_key_here
GROQ_PRIMARY_MODEL=llama-3.3-70b-versatile
GROQ_FALLBACK_MODEL=llama-3.1-70b-versatile

# Ollama Configuration (Local LLM - Privacy Focused)
OLLAMA_PRIMARY_MODEL=llama3.1:8b
OLLAMA_FALLBACK_MODEL=llama3.1:8b
OLLAMA_BASE_URL=http://localhost:11434

# AWS Bedrock Configuration (Enterprise LLM)
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-east-1
BEDROCK_PRIMARY_MODEL=anthropic.claude-3-haiku-20240307-v1:0
BEDROCK_FALLBACK_MODEL=amazon.titan-text-express-v1

# LangSmith Configuration (Optional - for tracing and monitoring)
LANGCHAIN_TRACING_V2=false
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=agentic-doc-processor

# Application Settings
DEBUG=false
LOG_LEVEL=INFO
